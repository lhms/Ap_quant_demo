{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import scipy.stats\n",
    "from numpy.linalg import inv\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_close_factors = pd.read_excel('https://github.com/lhms/Ap_quant_demo/blob/main/Sectors_sp500.xlsx')\n",
    "df_close_sectors = pd.read_excel('https://github.com/lhms/Ap_quant_demo/blob/main/df_close_sectors.xlsx')\n",
    "sp_sectors = pd.read_excel('https://github.com/lhms/Ap_quant_demo/blob/main/Sectors_sp500.xlsx')\n",
    "sp = pd.read_excel('https://github.com/lhms/Ap_quant_demo/blob/main/sp.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FACTORS - MERTON PORTFOLIO\n",
    "\n",
    "class merton_portfolio_fixed:\n",
    "    def __init__(self,data,weight,cost,minimum_lot,budget):\n",
    "        self.data = data # Primeira coluna: datas; segunda coluna: preços; terceira coluna: juros\n",
    "        self.weight = []\n",
    "        self.cost = cost #bps\n",
    "        self.minimum_lot = minimum_lot\n",
    "        self.budget = budget\n",
    "        \n",
    "        for i in range(0,len(self.data)):\n",
    "            self.weight.append(weight)\n",
    "        \n",
    "        \n",
    "        self.quantity = np.trunc(((self.budget*self.weight[0])/self.data.iloc[0,1])/self.minimum_lot)*self.minimum_lot\n",
    "        self.pl = []\n",
    "        self.pl.append([self.data.iloc[0,0],self.budget])\n",
    "        self.turnover = []\n",
    "        self.turnover.append(0)\n",
    "        \n",
    "        self.risk_free_hist = []\n",
    "        self.risky_asset_hist = []\n",
    "\n",
    "        self.risk_free = self.budget - self.quantity*self.data.iloc[0,1]\n",
    "        \n",
    "        self.risk_free_hist.append(self.risk_free)\n",
    "        self.risky_asset_hist.append(self.quantity*self.data.iloc[0,1])\n",
    "        \n",
    "\n",
    "          \n",
    "    def _iteration(self,i):\n",
    "        \n",
    "        price = self.data.iloc[i,1]\n",
    "        \n",
    "        actual_risky_asset = self.quantity*price\n",
    "        theoretical_risky_asset = self.pl[-1][1]*self.weight[i]\n",
    "\n",
    "        dif = actual_risky_asset - theoretical_risky_asset\n",
    "        \n",
    "        # Ajustando para deixar o peso fixo\n",
    "        \n",
    "        delta_equity = np.trunc((dif/price)/self.minimum_lot)*self.minimum_lot\n",
    "        \n",
    "        self.quantity -= delta_equity\n",
    "\n",
    "        \n",
    "        # Calculamos o turnover\n",
    "        \n",
    "        self.turnover.append(np.trunc((dif/price)/self.minimum_lot)*self.minimum_lot*price*self.cost*0.0001)\n",
    "        \n",
    "        # O PL do dia é o valor atual em equity + valor atual em cash - turnover\n",
    "        \n",
    "        self.risk_free += np.trunc((dif/price)/self.minimum_lot)*self.minimum_lot*price\n",
    "        # + self.risk_free - abs(self.turnover[-1]))\n",
    "        self.pl.append([self.data.iloc[i,0],self.quantity*price + self.risk_free - abs(self.turnover[-1])])\n",
    "        \n",
    "        self.risk_free_hist.append(self.risk_free)\n",
    "        self.risky_asset_hist.append(self.quantity*price)\n",
    "        \n",
    "        #print(self.pl)\n",
    "        \n",
    "    def _apply_rebal(self):\n",
    "        for i in range(1,len(self.data)):\n",
    "            self._iteration(i)\n",
    "\n",
    "            \n",
    "    def _apply_interest(self):\n",
    "        # Usa o FED funds como benchmark; subtrai o custo de oportunidade do risky asset, aplica no cash\n",
    "        for i in range(0,len(self.risky_asset_hist)):\n",
    "            int_rate = self.risky_asset_hist[i]*(1+self.data.iloc[i,2]/360)**(1/360) - self.risky_asset_hist[i]\n",
    "            self.risky_asset_hist[i] -= int_rate\n",
    "            \n",
    "            int_rate = self.risk_free_hist[i]*(1+self.data.iloc[i,2]/360)**(1/360) - self.risk_free_hist[i]\n",
    "            self.risk_free_hist[i]+=int_rate\n",
    "            \n",
    "            self.pl[i] = self.risk_free_hist[i] + self.risky_asset_hist[i] - abs(self.turnover[i])\n",
    "        \n",
    "    def get_pl(self):\n",
    "        return self.pl \n",
    "    def get_weight(self):\n",
    "        return self.weight \n",
    "    \n",
    "class merton_portfolio_drawdown(merton_portfolio_fixed):\n",
    "\n",
    "    def _adjust_weight(self,window,lower,upper):\n",
    "        # Ajustamos o peso de acordo com o drawdown\n",
    "        drawdown = np.zeros(len(self.data))\n",
    " #       w = np.zeros(len(self.data))\n",
    "#        w += self.weight[0]\n",
    "        for j in range(window,len(drawdown)):\n",
    "            drawdown[j] = (self.data.iloc[j,1] - max(self.data.iloc[j-window:j+1,1]))/max(self.data.iloc[j-window:j+1,1])\n",
    "            self.weight[j] = lower + (upper-lower)/(1+np.exp(10*drawdown[j]+2))\n",
    "#        return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apresentação - Demonstração de Modelos Quantitativos\n",
    "\n",
    "O objetivo da apresentação é demonstrar de maneira introdutória a utilização de técnicas de fatores, setores econômicos e Machine Learning na construção de portfólios de ETFs com o objetivo de desenvolver estratégias de investimento.\n",
    "\n",
    "Estrutura da apresentação:\n",
    "\n",
    "<ol>\n",
    "<li>Fatores de mercado</li>\n",
    "<li>Alocação e payoffs</li>\n",
    "<li>Pesos variáveis: modificando a solução de peso constante</li>\n",
    "<li>Construindo um portfolio de ETFs de fatores</li>\n",
    "<li>Introduzindo o aspecto econômico: rotação de setores via momemtum</li>\n",
    "<li>Market timing via Machine Learning</li>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### 1. Fatores de mercado\n",
    "\n",
    "#### Construção de um fator\n",
    "<ol>\n",
    "<li>Definição do universo de ativos elegíveis</li>\n",
    "<li>Definição de uma função de utilidade</li>\n",
    "<li>Criação de ranking. Z-score, por exemplo</li>\n",
    "<li>Definição do portfolio (long only/long-short); pesos e horizonte de rabalanceamento</li>\n",
    "</ol>\n",
    "\n",
    "Ex.: https://www.spglobal.com/spdji/en/indices/strategy/sp-500-momentum-index/#overview\n",
    "\n",
    "Em particular, sobre o fator momentum:\n",
    "\n",
    "Ref.: http://thierry-roncalli.com/download/Momentum_Risk_Premium.pdf\n",
    "\n",
    "Um aspecto interessante da referência acima é a constatação de que o fator momentum possui um \"payoff\" particular.\n",
    "\n",
    "### 2. Alocação e payoffs\n",
    "\n",
    "A prescição de alocação e rebalanceamento também induz \"payoffs\" particulares nos portfólios. Por exemplo, na paper:\n",
    "\n",
    "Ref.: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2465623\n",
    "\n",
    "Dito isso, é interessante definir portfolios com perfis de alocação/rebalanceamento de modo a contrabalancear o perfil de risco e payoff dos ativos subjacentes.\n",
    "\n",
    "Motivado pelas crises recentes, em particular os circuit-breakers gerados pelo Covid, vamos considerar duas metodologias de alocação que visam oferecer algum tipo de proteção contra eventos extremos.\n",
    "\n",
    "\n",
    "<ol>\n",
    "<li>Constant Proportion Portfolio Insurance (CPPI). <br>\n",
    "    <br>\n",
    "    Ex.: Black, F., and Perold, A. (1992), Theory of Constant Proportion Portfolio Insurance, Journal of Economic Dynamics and Control, 16(3-4), pp. 403-426.</li>\n",
    "<br>\n",
    "<li>Option-based Portfolio Insurance (OBPI)</li>\n",
    "    <br>\n",
    "    Ex.: Tail Risk Hedging: Creating Robust Portfolios for Volatile Markets (English Edition); Bhansali, Vineer <br>\n",
    "    Ex.: The second leg down: Strategies for Profiting After a Market Sell-Off; Krishnan, Hari\n",
    "    <br>\n",
    "</ol>\n",
    "\n",
    "Por simplicidade, vamos considerar o CPPI. A maneira mais simples de pensar no problema é considerar um portfolio com uma alocação fixa no ativo de risco (neste caso, o fator momentum, $S$) e em caixa, $C$.\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{dW}{W} = \\alpha \\frac{dS}{S} + (1-\\alpha) \\frac{dC}{C} = \\alpha \\frac{dS}{S}\n",
    "\\end{equation}\n",
    "\n",
    "Se $S$ segue um Movimento Browniano Geométrico:\n",
    "\n",
    "\\begin{equation}\n",
    "W = W_{0}\\left(\\frac{S}{S_{0}}\\right)^{\\alpha}exp\\left(-\\frac{1}{2}\\alpha (1-\\alpha)\\sigma^{2}t \\right)\n",
    "\\end{equation}\n",
    "\n",
    "O payoff é uma \"power option\", long ou short volatilidade\n",
    "\n",
    "<ul>\n",
    "<li>$\\alpha < 1$: tempo a favor (máximo em 0,5)</li>\n",
    "<li>$\\alpha > 1$: tempo contra </li>\n",
    "</ul>\n",
    "\n",
    "A solução que maximiza o acúmulo de riqueza ao longo do tempo quando o ativo subjacente segue um Movimento Browniano Geométrico (MBG) é dada pelo Portfolio de Merton.\n",
    "\n",
    "Ref.: http://bibliotecadigital.fgv.br/dspace/bitstream/handle/10438/24815/fgv_dissertacao_gustavo_VF.pdf?sequence=1&isAllowed=y\n",
    "\n",
    "Podemos atenuar o payoff similar a \"long vol\" do fator de momentum com um rebalanceamento baseado em proporções fixas, por exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fatores individuais e alocação constante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_ind(ETF):\n",
    "    \n",
    "    print(\"ETF - escala\")\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(df_close_factors[ETF]/df_close_factors[ETF].iloc[0])#-df_2/df_2.iloc[0])\n",
    "    plt.show()\n",
    "    \n",
    "    etf = merton_portfolio_drawdown(df_close_factors[['Dates',ETF]],0.5,300,10,1000000)\n",
    "    etf._adjust_weight(126,0.5,1)\n",
    "    etf._apply_rebal()\n",
    "    pl_ = pd.DataFrame(etf.get_pl())\n",
    "    \n",
    "    \n",
    "    print(\"Estratégia x ETF\")\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(pl_.iloc[:,1]/pl_.iloc[0,1])#-df_2/df_2.iloc[0])\n",
    "    #plt.plot(df_close['SPX Index']/df_close['SPX Index'].iloc[0])#-df_2/df_2.iloc[0])\n",
    "    plt.plot(df_close_factors[ETF]/df_close_factors[ETF].iloc[0])#-df_2/df_2.iloc[0])\n",
    "    plt.show()\n",
    "    \n",
    "#    print(\"EW - escala\")\n",
    "#    plt.figure(figsize=(10,5))\n",
    "#    plt.plot(pl_.iloc[:,1]/pl_.iloc[0,1])#-df_2/df_2.iloc[0])\n",
    "#    plt.show()\n",
    "#    print(\"SP500 - escala\")\n",
    "#    plt.figure(figsize=(10,5))\n",
    "#    plt.plot(df_close_factors['SPX Index']/df_close_factors['SPX Index'].iloc[0])#-df_2/df_2.iloc[0])\n",
    "#    plt.show()\n",
    "#    print(\"EW, SP500 - escala\")\n",
    "#    plt.figure(figsize=(10,5))\n",
    "#    plt.plot(pl_.iloc[:,1]/pl_.iloc[0,1])#-df_2/df_2.iloc[0])\n",
    "#    plt.plot(df_close_factors['SPX Index']/df_close_factors['SPX Index'].iloc[0])#-df_2/df_2.iloc[0])\n",
    "#    plt.show()\n",
    "    \n",
    "#    print(\"EW x Fed Funds\")\n",
    "#    plt.figure(figsize=(10,5))\n",
    "#    plt.plot(pl_.iloc[:,1]/pl_.iloc[0,1])#-df_2/df_2.iloc[0])\n",
    "    #plt.plot(df_close['SPX Index']/df_close['SPX Index'].iloc[0])#-df_2/df_2.iloc[0])  \n",
    "#    plt.plot(r)#-df_2/df_2.iloc[0])\n",
    "#    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "interact(factor_ind, ETF=['MTUM','VLUE','IUSG','QUAL']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pesos variáveis: modificando a solução de peso constante\n",
    "\n",
    "Na prática, não queremos manter o peso fixo o tempo inteiro, mas condicioná-lo a, digamos, o ciclo econômico em que nos encontramos. Tanto a expectativa de crescimento e a volatidade são condicionados a isso.\n",
    "\n",
    "Para ilustrar a ideia, vamos utilizar o drawdown para realizar o timing da alocação, e combinar com um portoflio de fatores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawdown\n",
    "\n",
    "Definição:\n",
    "\\begin{equation}\n",
    "DD = X(T) - {\\rm max}[X(t)], \\ t\\in (0,T)\n",
    "\\end{equation}\n",
    "\n",
    "O cálculo de um drawdown através de uma janela fixa apresenta \"periodicidade\" o sentido fraco do termo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SP500\")\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df_close_factors['SPX Index'].iloc[126:len(df_close_factors)-1].reset_index(drop=True)/df_close_factors['SPX Index'].iloc[126])#-df_2/df_2.iloc[0])\n",
    "plt.show()\n",
    "\n",
    "dd = []\n",
    "\n",
    "for i in range(126,len(df_close_factors['SPX Index'])-1):\n",
    "    dd.append((df_close_factors['SPX Index'].iloc[i] - max(df_close_factors['SPX Index'].iloc[i-126:i+1]))/max(df_close_factors['SPX Index'].iloc[i-126:i+1]))\n",
    "    \n",
    "print(\"Drawdown normalizado pelo máximo da janela, tendo 1 como nível de referência\")\n",
    "plt.figure(figsize=(10,5))\n",
    "draw = pd.Series(dd)+1\n",
    "plt.plot(draw)\n",
    "plt.show()\n",
    "\n",
    "print(\"Combinação\")\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df_close_factors['SPX Index'].iloc[126:len(df_close_factors)-1].reset_index(drop=True)/df_close_factors['SPX Index'].iloc[126])#-df_2/df_2.iloc[0])\n",
    "draw = pd.Series(dd)+1\n",
    "plt.plot(draw)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos diminuir a alocação quando nos encontramos no topo, esperando uma queda, e vamos aumentar a exposição no fundo, esperando uma recuperação. Essa abordagem é análoga ao portfolio de peso constante fixo, mas com um elemento de timing por um indicador que serve como uma \"proxy\" do ciclo econômico\n",
    "\n",
    "O peso do ativo em relação ao PL da estratégia é ajustado pelo drawdown via sigmoid (função logística):\n",
    "\n",
    "\\begin{equation}\n",
    "Peso = Min+ \\frac{Max-Min}{1+e^{10*DD+\\alpha}}\n",
    "\\end{equation}\n",
    "\n",
    "O portoflio é um conjunto de fatores, cada um rebalanceado contra caixa seguindo a metodologia acima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Construindo um portfolio de ETFs de fatores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula de inputs\n",
    "\n",
    "print(\"Lookback window for drawdown calculation (days)\")\n",
    "\n",
    "def init_look_f_port(x):\n",
    "    return x\n",
    "\n",
    "look_f_port = interactive(init_look_f_port, x= widgets.BoundedIntText(\n",
    "    value=126,\n",
    "    min=1,\n",
    "    max=252,\n",
    "    step=1,\n",
    "    description='Days:'))\n",
    "\n",
    "display(look_f_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Minimum allowed weight for the risky asset (frac)\")\n",
    "\n",
    "def init_min_w(x):\n",
    "    return x\n",
    "\n",
    "min_w = interactive(init_min_w, x= widgets.BoundedFloatText(\n",
    "    value=0.5,\n",
    "    min=0.1,\n",
    "    max=0.9,\n",
    "    step=0.01,\n",
    "    description='Frac:'))\n",
    "\n",
    "display(min_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum allowed weight for the risky asset (frac)\")\n",
    "\n",
    "def init_max_w(x):\n",
    "    return x\n",
    "\n",
    "max_w = interactive(init_max_w, x= widgets.BoundedFloatText(\n",
    "    value=1,\n",
    "    min=0.1,\n",
    "    max=1,\n",
    "    step=0.01,\n",
    "    description='Frac:'))\n",
    "\n",
    "display(max_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(\"Hedge - short SP500 (initial) (frac)\")\n",
    "\n",
    "#def init_hedge(x):\n",
    "#    return x\n",
    "\n",
    "#initial_hedge_perc = interactive(init_hedge, x= widgets.BoundedFloatText(\n",
    "#    value=0,\n",
    "#    min=0,\n",
    "#    max=1,\n",
    "#    step=0.01,\n",
    "#    description='Frac:'))\n",
    "\n",
    "#display(initial_hedge_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aloc1(x):\n",
    "    if x == 'Long only':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "al1 = interactive(aloc1, x=['Long only','Long/short 50% PL inicial em SP500'])\n",
    "display(al1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_portfolio(ETF):\n",
    "    \n",
    "        lookback_f_port = look_f_port.result\n",
    "        wmin_f_port = min_w.result\n",
    "        wmax_f_port = max_w.result\n",
    "       # initial_hedge = initial_hedge_perc.result\n",
    "    \n",
    "       # print(lookback_f_port,wmin_f_port,wmax_f_port,initial_hedge )\n",
    "        \n",
    "        assets = []\n",
    "        for e in ETF:\n",
    "            assets.append(merton_portfolio_drawdown(df_close_factors[['Dates',e]],0.5,300,10,1000000))\n",
    "\n",
    "\n",
    "        pls = []\n",
    "        for a in assets:\n",
    "            a._adjust_weight(lookback_f_port,wmin_f_port,wmax_f_port)\n",
    "            a._apply_rebal()\n",
    "            pls.append(pd.DataFrame(a.get_pl()))\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        for pl in pls:\n",
    "            df = pd.concat([df, pl.iloc[:,1]],axis=1)\n",
    "\n",
    "\n",
    "        pl_ = []\n",
    "\n",
    "        weights = np.zeros(len(df.columns))\n",
    "        weights += 1/len(df.columns)\n",
    "\n",
    "        budget = sum(df.iloc[0,:])\n",
    "\n",
    "        quantities = (weights*budget)/np.array(df.iloc[0,:])\n",
    "\n",
    "        pl_.append(budget)\n",
    "        #\n",
    "        for i in range(1,len(df)):\n",
    "            actual = quantities*np.array(df.iloc[i,:])\n",
    "\n",
    "            pl_.append(sum(actual))\n",
    "\n",
    "            quantities = (weights*sum(actual))/np.array(df.iloc[i,:])\n",
    "\n",
    "\n",
    "        pl_=pd.Series(pl_)\n",
    "\n",
    "        pl_ = pl_/pl_.iloc[0] \n",
    "        sp = df_close_factors['SPX Index']/df_close_factors['SPX Index'].iloc[0]\n",
    "\n",
    "        if al1.result == False:\n",
    "            pl_ = pl_ - 0.5*sp  \n",
    "        \n",
    "\n",
    "        print(\"Estratégia - escala\")\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(pl_)#-df_2/df_2.iloc[0])\n",
    "        plt.show()\n",
    "        print(\"SP500 - escala\")\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(df_close_factors['SPX Index']/df_close_factors['SPX Index'].iloc[0])#-df_2/df_2.iloc[0])\n",
    "        plt.show()\n",
    "        print(\"Estratégia, SP500 - escala\")\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(pl_)#-df_2/df_2.iloc[0])\n",
    "        plt.plot(df_close_factors['SPX Index']/df_close_factors['SPX Index'].iloc[0])#-df_2/df_2.iloc[0])\n",
    "        plt.show()\n",
    "\n",
    "    #    print(\"EW x Fed Funds\")\n",
    "    #    plt.figure(figsize=(10,5))\n",
    "    #    plt.plot(pl_.iloc[:,1]/pl_.iloc[0,1])#-df_2/df_2.iloc[0])\n",
    "        #plt.plot(df_close['SPX Index']/df_close['SPX Index'].iloc[0])#-df_2/df_2.iloc[0])  \n",
    "    #    plt.plot(r)#-df_2/df_2.iloc[0])\n",
    "    #    plt.show()\n",
    "\n",
    "\n",
    "interact(factor_portfolio, ETF= widgets.SelectMultiple(\n",
    "    options=['MTUM','VLUE','IUSG','QUAL'],\n",
    "    value = ['MTUM'],\n",
    "    description='Factors'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Introduzindo o aspecto econômico: rotação de setores via momemtum\n",
    "\n",
    "Uma forma de envolver o aspecto macroeconômico é escolher fatores baseados em um ranking de momentum.\n",
    "\n",
    "\\begin{equation}\n",
    "M = sign(Retorno\\ passado \\ em \\ janela \\ \\Delta t) ∗ [\\% retornos \\ negativos −\\% retornos \\ positivos]\n",
    "\\end{equation}\n",
    "\n",
    "Obs.: Sejam $t_{1}$ e $t_{2}$ dois horizontes de tempo. A janela é calculada como retornos de -252-21 dias até -21 dias. Excluímos os retornos de $t_{2}$, no caso, o mês mais recente.\n",
    "\n",
    "Ref: Quantitative momentum: a practitioner’s guide to building a momentum-based stock selection system; Wesley R. Gray, Jack R. Vogel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sector_rotation_fixed_weight:\n",
    "    def __init__(self,data,number_of_sectors,cost,minimum_lot,budget,window1,window2,horizon):\n",
    "        self.data = data # Primeira coluna: datas; a partir da segunda coluna: preços, última: juros\n",
    "        self.number_of_sectors = number_of_sectors\n",
    "        self.window1 = window1\n",
    "        self.window2 = window2\n",
    "        self.horizon = horizon\n",
    "        self.weight = []\n",
    "        self.cost = cost #bps\n",
    "        self.minimum_lot = minimum_lot\n",
    "        self.budget = budget\n",
    "        self.quantity = np.zeros(len(self.data.columns)-2)\n",
    "        \n",
    "        w = np.zeros(number_of_sectors)\n",
    "        \n",
    "        for i in range(0,len(self.data)):\n",
    "            self.weight.append(w)\n",
    "        \n",
    "        for i in range(0,number_of_sectors):\n",
    "            self.quantity[i] = np.trunc(((self.budget*self.weight[0][i])/self.data.iloc[0,i+1])/self.minimum_lot)*self.minimum_lot\n",
    "        self.pl = []\n",
    "        self.pl.append([self.data.iloc[0,0],self.budget])\n",
    "        self.turnover = []\n",
    "        self.turnover.append(0)\n",
    "        \n",
    "        self.scores = []\n",
    "        \n",
    "    def _ranking(self,i): #Tem que vir depois do _iteração\n",
    "        scores = []\n",
    "        \n",
    "        for j in range(1,len(self.data.columns)-1):\n",
    "            hist = self.data.iloc[i-self.window1-self.window2:i-self.window2+1,j]\n",
    "            hist = list(hist.astype(float).apply(np.log).diff().dropna(how='any').reset_index(drop=True))\n",
    "            \n",
    "            signal = sum(hist)/abs(sum(hist))\n",
    "            \n",
    "            neg_count = len(list(filter(lambda x: (x < 0), hist)))/len(hist)\n",
    "            pos_count = len(list(filter(lambda x: (x >= 0), hist)))/len(hist)\n",
    "            \n",
    "            scores.append([signal*(pos_count-neg_count),j])\n",
    "            scores.sort(key=lambda tup: tup[0], reverse=True)\n",
    "        \n",
    "        # Já temos os scores ordenados do maior para o menor\n",
    "        norm = 0\n",
    "        for j in range(0,len(scores)):\n",
    "            if j<self.number_of_sectors:\n",
    "                scores[j][0] = 1/self.number_of_sectors # Peso igual\n",
    " #               scores[j][0] = 1/(j+1)**2\n",
    "#                norm+=1/(j+1)**2\n",
    "            else:\n",
    "                scores[j][0] = 0\n",
    "                \n",
    "#        for j in range(0,len(scores)): \n",
    "#            scores[j][0] = scores[j][0]/norm\n",
    "        \n",
    "        # Devolvendo para a ordem inicial, baseada em colunas\n",
    "        \n",
    "        scores.sort(key=lambda tup: tup[1])\n",
    "        # Neste ponto, os scores correspondem aos pesos relativos. Vamos converter para quantidade de ações,\n",
    "        # calcular o turnover, e redefinir o vetor de quantidades.\n",
    "        \n",
    "        q = np.zeros(len(self.data.columns)-2)\n",
    "        t = 0\n",
    "        for j in range(0,len(scores)):\n",
    "            q[j] = np.trunc(((self.pl[-1][1]*scores[j][0])/self.data.iloc[i,j+1])/self.minimum_lot)*self.minimum_lot\n",
    "            dif = self.quantity[j]-q[j]\n",
    "            t+=abs(np.trunc((dif/self.data.iloc[i,j+1])/self.minimum_lot)*self.minimum_lot*self.data.iloc[i,j+1]*self.cost*0.0001)\n",
    "                \n",
    "        \n",
    "        self.turnover.append(t)\n",
    "\n",
    "        self.pl[-1][1] -= t\n",
    "        \n",
    "        self.quantity = q\n",
    "            \n",
    "            \n",
    "    def _iteration(self,i):\n",
    "        \n",
    "        price = np.array(self.data.iloc[i,1:-1])\n",
    "\n",
    "        self.pl.append([self.data.iloc[i,0],sum(self.quantity*price)])\n",
    "        \n",
    "        \n",
    "    def _apply_rebal(self):\n",
    "        for i in range(self.window1+self.window2,len(self.data)):\n",
    "            if i == self.window1+self.window2:\n",
    "                self._ranking(i)\n",
    "            else: \n",
    "                self._iteration(i)\n",
    "                if i%self.horizon==0:\n",
    "                    self._ranking(i)\n",
    "            #print(self.quantity)\n",
    "    \n",
    "    def get_pl(self):\n",
    "        return self.pl \n",
    "    def get_quantities(self):\n",
    "        return self.quantity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lista de ETFs usados: 'XLK', 'XLC', 'XLY', 'XLI', 'XLB', 'XLF', 'XLE', 'XLV', 'XLP', 'XLRE', 'XLU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula de inputs\n",
    "\n",
    "print(\"Lookback window 1 (days)\")\n",
    "\n",
    "def init_look_f_port(x):\n",
    "    return x\n",
    "\n",
    "look_f_port1 = interactive(init_look_f_port, x= widgets.BoundedIntText(\n",
    "    value=63,\n",
    "    min=1,\n",
    "    max=252,\n",
    "    step=1,\n",
    "    description='Days:'))\n",
    "\n",
    "display(look_f_port1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula de inputs\n",
    "\n",
    "print(\"Lookback window 2 (days)\")\n",
    "\n",
    "def init_look_f_port(x):\n",
    "    return x\n",
    "\n",
    "look_f_port2 = interactive(init_look_f_port, x= widgets.BoundedIntText(\n",
    "    value=21,\n",
    "    min=1,\n",
    "    max=252,\n",
    "    step=1,\n",
    "    description='Days:'))\n",
    "\n",
    "display(look_f_port2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula de inputs\n",
    "\n",
    "print(\"Rebalancing horizon (days)\")\n",
    "\n",
    "def init_look_f_port(x):\n",
    "    return x\n",
    "\n",
    "horizon = interactive(init_look_f_port, x= widgets.BoundedIntText(\n",
    "    value=21,\n",
    "    min=1,\n",
    "    max=252,\n",
    "    step=1,\n",
    "    description='Days:'))\n",
    "\n",
    "display(horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PL(t=0) Hedge (short SP500)\")\n",
    "\n",
    "def init_min_w(x):\n",
    "    return x\n",
    "\n",
    "hedge_sector = interactive(init_min_w, x= widgets.BoundedFloatText(\n",
    "    value=0.5,\n",
    "    min=0,\n",
    "    max=1,\n",
    "    step=0.01,\n",
    "    description='Frac:'))\n",
    "\n",
    "display(hedge_sector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula de inputs\n",
    "\n",
    "print(\"N ativos\")\n",
    "\n",
    "def ativos(x):\n",
    "    return x\n",
    "\n",
    "a = interactive(ativos, x= widgets.BoundedIntText(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=11,\n",
    "    step=1,\n",
    "    description='N de ativos:'))\n",
    "\n",
    "display(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aloc(x):\n",
    "    if x == 'Long only':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "al = interactive(aloc, x=['Long only','Long/short SP500'])\n",
    "display(al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def f_sector(b):\n",
    "    \n",
    "    with output:\n",
    "        clear_output()\n",
    "        ETF=['XLK','XLC','XLY','XLI','XLB','XLF','XLE','XLV','XLP','XLRE','XLU']\n",
    "    #    print(\"ETF - escala\")\n",
    "    #    plt.figure(figsize=(10,5))\n",
    "    #    plt.plot(df_close_sectors[ETF]/df_close_sectors[ETF].iloc[0])#-df_2/df_2.iloc[0])\n",
    "    #    plt.show()\n",
    "\n",
    "\n",
    "        etf = sector_rotation_fixed_weight(pd.concat([df_close_sectors['Dates'],df_close_sectors.iloc[:,3:]],axis=1),int(a.result),300,\n",
    "                                           10,1000000,look_f_port1.result,look_f_port2.result,horizon.result)\n",
    "        #etf._adjust_weight(126,0.5,1)\n",
    "        etf._apply_rebal()\n",
    "        pl_ = pd.DataFrame(etf.get_pl())\n",
    "\n",
    "        if al.result == False:\n",
    "\n",
    "            pl_hedge = pl_.iloc[:,1]/pl_.iloc[0,1] - hedge_sector.result*sp.iloc[-len(pl_):,1].reset_index(drop=True)/sp.iloc[-len(pl_),1]\n",
    "            pl_hedge += 1 - pl_hedge.iloc[0]\n",
    "        else:\n",
    "            pl_hedge = pl_.iloc[:,1]/pl_.iloc[0,1]\n",
    "\n",
    "\n",
    "        print(\"PL - escala\")\n",
    "        plt.figure(figsize=(10,5))\n",
    "        #plt.plot(pl_.iloc[:,1]/pl_.iloc[0,1])#-df_2/df_2.iloc[0])\n",
    "        plt.plot(pl_hedge)#/pl_hedge.iloc[0])\n",
    "        plt.show()\n",
    "        print(\"Ativo - escala\")\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(sp.iloc[-len(pl_):,1].reset_index(drop=True)/sp.iloc[-len(pl_),1])#-df_2/df_2.iloc[0])\n",
    "        plt.show()\n",
    "\n",
    "        print(\"PL e ativo - escala\")\n",
    "        plt.figure(figsize=(10,5))\n",
    "        #plt.plot(pl_.iloc[:,1]/pl_.iloc[0,1])#-df_2/df_2.iloc[0])\n",
    "        plt.plot(pl_hedge)#/pl_hedge.iloc[0])\n",
    "        plt.plot(sp.iloc[-len(pl_):,1].reset_index(drop=True)/sp.iloc[-len(pl_),1])#-df_2/df_2.iloc[0])\n",
    "        plt.show()\n",
    "\n",
    "    #    print(\"EW x ETF\")\n",
    "    #    plt.figure(figsize=(10,5))\n",
    "    #    #plt.plot(pl_.iloc[:,1]/pl_.iloc[0,1])#-df_2/df_2.iloc[0])\n",
    "    #    plt.plot(pl_hedge/pl_hedge.iloc[0])\n",
    "        #plt.plot(df_close['SPX Index']/df_close['SPX Index'].iloc[0])#-df_2/df_2.iloc[0])\n",
    "    #    plt.plot(df_close_sectors[ETF].iloc[-len(pl_):].reset_index(drop=True)/df_close_sectors[ETF].iloc[-len(pl_)])#-df_2/df_2.iloc[0])\n",
    "        plt.show()\n",
    "    #\n",
    "        return\n",
    "\n",
    "\n",
    "button = widgets.Button(description=\"OK\")\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "display(button, output)\n",
    "\n",
    "button.on_click(f_sector)\n",
    "\n",
    "#start_button = widgets.Button(description='OK')\n",
    "# Trocar por um botão de OK\n",
    "#interact(f, ETF=['XLK','XLC','XLY','XLI','XLB','XLF','XLE','XLV','XLP','XLRE','XLU']);\n",
    "#display(start_button)\n",
    "#start_button.on_click(f(ETF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Market timing via Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A utilidade de ML é a possibilidade de combinar fatores/indicadores que, isoladamente, possuem uma capacidade preditiva limitada em algo que apresenta uma performance muito superior.\n",
    "\n",
    "Vamos construir uma base de dados envolvendo os índices de setores disponíveis em https://www.spglobal.com/spdji/en/index-family/strategy/ . O motivo é simplesmente expandir o histórico (os ETFs usados anteriormente tem um horizonte mais limitado) para treinamos uma Decision Tree\n",
    "\n",
    "Os índices usados são:\n",
    "\n",
    "<ul>\n",
    "<li>Consumer_discretionary</li>\n",
    "<li>Consumer_staples</li>\n",
    "<li>Energy</li>\n",
    "<li>Financials</li>\n",
    "<li>Health Care</li>\n",
    "<li>Industrials</li>\n",
    "<li>Tech</li>\n",
    "<li>Materials</li>\n",
    "<li>Communication_services</li>\n",
    "<li>Utilities</li>\n",
    "<li>Commodities_GSCI (índices de commodities)</li>\n",
    "<li>DJ_FXCM_Dollar_Index (índice de moedas)</li>\n",
    "<li>SP500</li>\n",
    "</ul>\n",
    "\n",
    "E os indicadores construídos são:\n",
    "\n",
    "<ul>\n",
    "<li>Momentum, janela 126</li>\n",
    "<li>Drawdown, janela 126</li>\n",
    "</ul>\n",
    "\n",
    "Construção da resposta do algoritmo:\n",
    "\n",
    "<ul>\n",
    "    <li>Retorno do ativo 21 dias adiante</li>\n",
    "</ul>\n",
    "\n",
    "Backtest: últimos 504+21 dias (final de 2019, 2020 e parte de 2021). A probabilidade retornada pelo algoritmo é utilizada para construir o peso do ativo, em um portfolio caixa + ativo, segundo:\n",
    "\n",
    "\\begin{equation}\n",
    "Peso = 0.1 + \\frac{0.9}{1+e^{-Prob^{2}}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_feat = pd.read_excel('https://github.com/lhms/Ap_quant_demo/blob/main/sp_feat.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(sp_sectors.columns)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_sectors_ = sp_sectors.copy()\n",
    "sp_sectors_.iloc[:,1:] = sp_sectors_.iloc[:,1:].apply(np.log).diff().dropna(how='any').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp_feat = sp_feat.iloc[126:,:]\n",
    "sp_sectors_ = sp_sectors_.iloc[126:,:]\n",
    "sp_sectors = sp_sectors.iloc[126:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_feat = sp_feat.reset_index(drop=True)\n",
    "sp_sectors_ = sp_sectors_.reset_index(drop=True)\n",
    "sp_sectors = sp_sectors.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_sector(x):\n",
    "        return x\n",
    "\n",
    "nm = interactive(name_sector, x=['Consumer_discretionary', 'Consumer_staples', 'Energy', 'Financials', 'Health Care', 'Industrials', 'Tech', 'Materials', 'Communication_services', 'Utilities', 'Commodities_GSCI', 'SP500', 'DJ_FXCM_Dollar_Index'])\n",
    "display(nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "\n",
    "# function for fitting trees of various depths on the training data using cross-validation\n",
    "def run_cross_validation_on_trees(X, y, tree_depths, cv=30, scoring='accuracy'):\n",
    "    cv_scores_list = []\n",
    "    cv_scores_std = []\n",
    "    cv_scores_mean = []\n",
    "    accuracy_scores = []\n",
    "    for depth in tree_depths:\n",
    "        tree_model = DecisionTreeClassifier(max_depth=depth)\n",
    "        cv_scores = cross_val_score(tree_model, X, y, cv=cv, scoring=scoring)\n",
    "        cv_scores_list.append(cv_scores)\n",
    "        cv_scores_mean.append(cv_scores.mean())\n",
    "        cv_scores_std.append(cv_scores.std())\n",
    "        accuracy_scores.append(tree_model.fit(X, y).score(X, y))\n",
    "    cv_scores_mean = np.array(cv_scores_mean)\n",
    "    cv_scores_std = np.array(cv_scores_std)\n",
    "    accuracy_scores = np.array(accuracy_scores)\n",
    "    return cv_scores_mean, cv_scores_std, accuracy_scores\n",
    "  \n",
    "# function for plotting cross-validation results\n",
    "def plot_cross_validation_on_trees(depths, cv_scores_mean, cv_scores_std, accuracy_scores, title):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "    ax.plot(depths, cv_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)\n",
    "    ax.fill_between(depths, cv_scores_mean-2*cv_scores_std, cv_scores_mean+2*cv_scores_std, alpha=0.2)\n",
    "    ylim = plt.ylim()\n",
    "    ax.plot(depths, accuracy_scores, '-*', label='train accuracy', alpha=0.9)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel('Tree depth', fontsize=14)\n",
    "    ax.set_ylabel('Accuracy', fontsize=14)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_xticks(depths)\n",
    "    ax.legend()\n",
    "    \n",
    "def run_single_tree(X_train, y_train, X_test, y_test, depth):\n",
    "    model = DecisionTreeClassifier(max_depth=depth).fit(X_train, y_train)\n",
    "    accuracy_train = model.score(X_train, y_train)\n",
    "    accuracy_test = model.score(X_test, y_test)\n",
    "    print('Single tree depth: ', depth)\n",
    "    print('Accuracy, Training Set: ', round(accuracy_train*100,5), '%')\n",
    "    print('Accuracy, Test Set: ', round(accuracy_test*100,5), '%')\n",
    "    return accuracy_train, accuracy_test\n",
    "\n",
    "def f_sector_ml(b2):\n",
    "    \n",
    "    with output2:\n",
    "        clear_output()\n",
    "       \n",
    "        forward = 21\n",
    "        initial = 0\n",
    "\n",
    "        X = sp_feat.iloc[initial:len(sp_feat)-504-forward,:].reset_index(drop=True)\n",
    "        backtest = sp_feat.iloc[len(sp_feat)-504-forward:,:].reset_index(drop=True)\n",
    "\n",
    "        name = nm.result\n",
    "\n",
    "        resp = []\n",
    "\n",
    "        for i in range(initial,len(sp_feat)-504-forward):\n",
    "            if sum(sp_sectors_[name].iloc[i:i+forward])>0:\n",
    "                resp.append(1)\n",
    "            else:\n",
    "                resp.append(0)\n",
    "\n",
    "        # fitting trees of depth 1 to 24\n",
    "        sm_tree_depths = range(1,25)\n",
    "        sm_cv_scores_mean, sm_cv_scores_std, sm_accuracy_scores = run_cross_validation_on_trees(X, pd.Series(resp), sm_tree_depths)\n",
    "\n",
    "        # plotting accuracy\n",
    "        plot_cross_validation_on_trees(sm_tree_depths, sm_cv_scores_mean, sm_cv_scores_std, sm_accuracy_scores, \n",
    "                                       'Accuracy per decision tree depth on training data')\n",
    "\n",
    "        idx_max = sm_cv_scores_mean.argmax()\n",
    "        sm_best_tree_depth = sm_tree_depths[idx_max]\n",
    "        sm_best_tree_cv_score = sm_cv_scores_mean[idx_max]\n",
    "        sm_best_tree_cv_score_std = sm_cv_scores_std[idx_max]\n",
    "        print('The depth-{} tree achieves the best mean cross-validation accuracy {} +/- {}% on training dataset'.format(\n",
    "              sm_best_tree_depth, round(sm_best_tree_cv_score*100,5), round(sm_best_tree_cv_score_std*100, 5)))\n",
    "\n",
    "        if sm_best_tree_depth == 1:\n",
    "            sm_best_tree_depth +=1\n",
    "        \n",
    "        clf = tree.DecisionTreeClassifier(max_depth=sm_best_tree_depth,random_state=0)\n",
    "\n",
    "        #clf = LogisticRegressionCV(cv=20,random_state=0,max_iter =1000)\n",
    "        clf = clf.fit(X, pd.Series(resp))\n",
    "\n",
    "        pred = clf.predict_proba(np.matrix(backtest))\n",
    "        b = sp_sectors_[name].iloc[len(sp_sectors_)-504-forward:].reset_index(drop=True)\n",
    "\n",
    "\n",
    "        pred_ = pd.DataFrame(pred)\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(pred_.iloc[:,1])\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(b.cumsum())\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(pred_.iloc[:,1])\n",
    "        plt.plot(b.cumsum())\n",
    "        plt.show()\n",
    "\n",
    "        ret = []\n",
    "\n",
    "        for i in range(0,len(b)-1):\n",
    "            ret.append((0.1 + 0.9/(1+np.exp(-pred_.iloc[i,1]**2)))*b.iloc[i+1])\n",
    "\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(pd.Series(ret[forward:]).cumsum())\n",
    "        plt.plot(b.iloc[forward:].reset_index(drop=True).cumsum())\n",
    "        plt.show()\n",
    "\n",
    "        return\n",
    "\n",
    "button2 = widgets.Button(description=\"OK\")\n",
    "output2 = widgets.Output()\n",
    "\n",
    "\n",
    "display(button2, output2)\n",
    "\n",
    "button2.on_click(f_sector_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
